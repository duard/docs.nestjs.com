
<div class="content" #contentReference>
  <div class="github-links">
    <a
      href="https://github.com/nestjs/docs.nestjs.com/edit/master/content/techniques/queues.md"
      aria-label="Suggest Edits"
      title="Suggest Edits"
    >
      <i class="fas fa-edit"></i>
    </a>
  </div>
  <h3 id="queues">Queues</h3>
<p>Queues are a powerful design pattern that help you deal with common application scaling and performance challenges. Some examples of problems that Queues can help you solve are:</p>
<ul>
<li>Smooth out processing peaks. For example, if users can initiate resource-intensive tasks at arbitrary times, you can add these tasks to a queue instead of performing them synchronously. Then you can have worker processes pull tasks from the queue in a controlled manner. You can easily add new Queue consumers to scale up the back-end task handling as the application scales up.</li>
<li>Break up monolithic tasks that may otherwise block the Node.js event loop. For example, if a user request requires CPU intensive work like audio transcoding, you can delegate this task to other processes, freeing up user-facing processes to remain responsive.</li>
<li>Provide a reliable communication channel across various services. For example, you can queue tasks (jobs) in one process or service, and consume them in another. You can be notified (by listening for status events) upon completion, error or other state changes in the job life cycle from any process or service. When Queue producers or consumers fail, their state is preserved and task handling can restart automatically when nodes are restarted.</li>
</ul>
<p>Nest provides the <code>@nestjs/bull</code> package as an abstraction/wrapper on top of <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull">Bull</a>, a popular, well supported, high performance Node.js based Queue system implementation. The package makes it easy to integrate Bull Queues in a Nest-friendly way to your application.</p>
<p>Bull uses <a rel='nofollow' target='_blank' href="https://redis.io/">Redis</a> to persist job data, so you&#39;ll need to have Redis installed on your system. Because it is Redis-backed, your Queue architecture can be completely distributed and platform-independent. For example, you can have some Queue <a href="techniques/queues#producers">producers</a> and <a href="techniques/queues#consumers">consumers</a> and <a href="techniques/queues#event-listeners">listeners</a> running in Nest on one (or several) nodes, and other producers, consumers and listeners running on other Node.js platforms on other network nodes.</p>
<p>This chapter covers the <code>@nestjs/bull</code> package. We also recommend reading the <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md">Bull documentation</a> for more background and specific implementation details.</p>
<h4 appAnchor id="installation"><span>Installation</span></h4>
<p>To begin using it, we first install the required dependencies.</p>
<pre><code class="language-bash">
$ npm install --save @nestjs/bull bull
$ npm install --save-dev @types/bull</code></pre>
<p>Once the installation process is complete, we can import the <code>BullModule</code> into the root <code>AppModule</code>.</p>

<span class="filename">
  {{ 'app.module' | extension: app8f6566f5ae01f4b49bf3bc544e70f77ba2814dd9.isJsActive }}
<app-tabs #app8f6566f5ae01f4b49bf3bc544e70f77ba2814dd9></app-tabs>
</span><pre><code class="language-typescript">
import &#123; Module &#125; from &#39;@nestjs/common&#39;;
import &#123; BullModule &#125; from &#39;@nestjs/bull&#39;;

@Module(&#123;
  imports: [
    BullModule.registerQueue(&#123;
      name: &#39;audio&#39;,
      redis: &#123;
        host: &#39;localhost&#39;,
        port: 6379,
      &#125;,
    &#125;),
  ],
&#125;)
export class AppModule &#123;&#125;</code></pre><p>The <code>registerQueue()</code> method is used to instantiate and/or register queues. Queues are shared across modules and processes that connect to the same underlying Redis database with the same credentials. Each queue is unique by its name property (see below). When sharing queues (across modules/processes), the first <code>registerQueue()</code> method to run both <strong>instantiates</strong> the queue and <strong>registers</strong> it for that module. Other modules (in the same or separate processes) simply <strong>register</strong> the queue. Queue registration creates an <strong>injection token</strong> that can be used to access the queue in a given Nest module.</p>
<p>For each queue, pass a configuration object containing the following properties:</p>
<ul>
<li><code>name: string</code> - A queue name, which will be used as both an injection token (for injecting the queue into controllers/providers), and as an argument to decorators to associate consumer classes and listeners with queues. Required.</li>
<li><code>limiter: RateLimiter</code> - Options to control the rate at which the queue&#39;s jobs are processed. See <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queue">RateLimiter</a> for more information. Optional.</li>
<li><code>redis: RedisOpts</code> - Options to configure the Redis connection. See <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queue">RedisOpts</a> for more information. Optional.</li>
<li><code>prefix: string</code> - Prefix for all queue keys. Optional.</li>
<li><code>defaultJobOptions: JobOpts</code> - Options to control the default settings for new jobs. See <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queueadd">JobOpts</a> for more information. Optional.</li>
<li><code>settings: AdvancedSettings</code> - Advanced Queue configuration settings. These should usually not be changed. See <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queue">AdvancedSettings</a> for more information. Optional.</li>
</ul>
<p>As noted, the <code>name</code> property is required. The rest of the options are optional, providing detailed control over queue behavior. These are passed directly to the Bull <code>Queue</code> constructor. Read more about these options <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queue">here</a>. When registering a queue in a second or subsequent module, it is best practice to omit all options but the <code>name</code> property from the configuration object. These options should be specified only in the module that <strong>instantiates</strong> the queue.</p>
<blockquote class="
info "><strong>Hint</strong> Create multiple queues by passing multiple comma-separated configuration objects to the <code>registerQueue()</code> method.
</blockquote>
<p>Since jobs are persisted in Redis, each time a specific named queue is instantiated (e.g., when an app is started/restarted), it attempts to process any old jobs that may exist from a previous unfinished session.</p>
<p>Each queue can have one or many producers, consumers, and listeners. Consumers retrieve jobs from the queue in a specific order: FIFO (the default), LIFO, or according to priorities. Controlling queue processing order is discussed <a href="techniques/queues#consumers">here</a>.</p>
<h4 appAnchor id="producers"><span>Producers</span></h4>
<p>Job producers add jobs to queues. Producers are typically application services (Nest <a routerLink="/providers">providers</a>). To add jobs to a queue, first inject the queue into the service as follows:</p>
<pre><code class="language-typescript">
import &#123; Injectable &#125; from &#39;@nestjs/common&#39;;
import &#123; Queue &#125; from &#39;bull&#39;;
import &#123; InjectQueue &#125; from &#39;@nestjs/bull&#39;;

@Injectable()
export class AudioService &#123;
  constructor(@InjectQueue(&#39;audio&#39;) private readonly audioQueue: Queue) &#123;&#125;
&#125;</code></pre>
<blockquote class="
info "><strong>Hint</strong> The <code>@InjectQueue()</code> decorator identifies the queue by its name, as provided in the <code>registerQueue()</code> method call (e.g., <code>&#39;audio&#39;</code>).
</blockquote>
<p>Now, add a job by calling the queue&#39;s <code>add()</code> method, passing a user-defined job object. Jobs are represented as serializable JavaScript objects (since that is how they are stored in the Redis database). The shape of the job you pass is arbitrary; use it to represent the semantics of your job object.</p>
<pre><code class="language-typescript">
const job = await this.audioQueue.add(&#123;
  foo: &#39;bar&#39;,
&#125;);</code></pre>
<h4 appAnchor id="named-jobs"><span>Named jobs</span></h4>
<p>Jobs may have unique names. This allows you to create specialized <a href="techniques/queues#consumers">consumers</a> that will only process jobs with a given name.</p>
<pre><code class="language-typescript">
const job = await this.audioQueue.add(&#39;transcode&#39;, &#123;
  foo: &#39;bar&#39;,
&#125;);</code></pre>
<blockquote class="
Warning "><strong>Warning</strong> When using named jobs, you must create processors for each unique name added to a queue, or the queue will complain that you are missing a processor for the given job. See <a href="techniques/queues#consumers">here</a> for more information on consuming named jobs.
</blockquote>
<h4 appAnchor id="job-options"><span>Job options</span></h4>
<p>Jobs can have additional options associated with them. Pass an options object after the <code>job</code> argument in the <code>Queue.add()</code> method. Job options properties are:</p>
<ul>
<li><code>priority</code>: <code>number</code> - Optional priority value. Ranges from 1 (highest priority) to MAX_INT (lowest priority). Note that using priorities has a slight impact on performance, so use them with caution.</li>
<li><code>delay</code>: <code>number</code> - An amount of time (milliseconds) to wait until this job can be processed. Note that for accurate delays, both server and clients should have their clocks synchronized.</li>
<li><code>attempts</code>: <code>number</code> - The total number of attempts to try the job until it completes.</li>
<li><code>repeat</code>: <code>RepeatOpts</code> - Repeat job according to a cron specification. See <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queueadd">RepeatOpts</a>.</li>
<li><code>backoff</code>: <code>number | BackoffOpts</code> - Backoff setting for automatic retries if the job fails. See <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queueadd">BackoffOpts</a>.</li>
<li><code>lifo</code>: <code>boolean</code> - If true, adds the job to the right end of the queue instead of the left (default false).</li>
<li><code>timeout</code>: <code>number</code> - The number of milliseconds after which the job should fail with a timeout error.</li>
<li><code>jobId</code>: <code>number</code> | <code>string</code> - Override the job ID - by default, the job ID is a unique
integer, but you can use this setting to override it. If you use this option, it is up to you to ensure the jobId is unique. If you attempt to add a job with an id that already exists, it will not be added.</li>
<li><code>removeOnComplete</code>: <code>boolean | number</code> - If true, removes the job when it successfully completes. A number specifies the amount of jobs to keep. Default behavior is to keep the job in the completed set.</li>
<li><code>removeOnFail</code>: <code>boolean | number</code> - If true, removes the job when it fails after all attempts. A number specifies the amount of jobs to keep. Default behavior is to keep the job in the failed set.</li>
<li><code>stackTraceLimit</code>: <code>number</code> - Limits the amount of stack trace lines that will be recorded in the stacktrace.</li>
</ul>
<p>Here are a few examples of customizing jobs with job options.</p>
<p>To delay the start of a job, use the <code>delay</code> configuration property.</p>
<pre><code class="language-typescript">
const job = await this.audioQueue.add(
  &#123;
    foo: &#39;bar&#39;,
  &#125;,
  &#123; delay: 3000 &#125;, // 3 seconds delayed
);</code></pre>
<p>To add a job to the right end of the queue (process the job as <strong>LIFO</strong> (Last In First Out)), set the <code>lifo</code> property of the configuration object to <code>true</code>.</p>
<pre><code class="language-typescript">
const job = await this.audioQueue.add(
  &#123;
    foo: &#39;bar&#39;,
  &#125;,
  &#123; lifo: true &#125;,
);</code></pre>
<p>To prioritize a job, use the <code>priority</code> property.</p>
<pre><code class="language-typescript">
const job = await this.audioQueue.add(
  &#123;
    foo: &#39;bar&#39;,
  &#125;,
  &#123; priority: 2 &#125;,
);</code></pre>
<h4 appAnchor id="consumers"><span>Consumers</span></h4>
<p>A consumer is a <strong>class</strong> defining methods that either process jobs added into the queue, or listen for events on the queue, or both. Declare a consumer class using the <code>@Processor()</code> decorator as follows:</p>
<pre><code class="language-typescript">
import &#123; Processor &#125; from &#39;@nestjs/bull&#39;;

@Processor(&#39;audio&#39;)
export class AudioConsumer &#123;&#125;</code></pre>
<p>Where the decorator&#39;s string argument (e.g., <code>&#39;audio&#39;</code>) is the name of the queue to be associated with the class methods.</p>
<p>Within a consumer class, declare job handlers by decorating handler methods with the <code>@Process()</code> decorator.</p>
<pre><code class="language-typescript">
import &#123; Processor, Process &#125; from &#39;@nestjs/bull&#39;;
import &#123; Job &#125; from &#39;bull&#39;;

@Processor(&#39;audio&#39;)
export class AudioConsumer &#123;
  @Process()
  async transcode(job: Job&lt;unknown&gt;) &#123;
    let progress = 0;
    for (i = 0; i &lt; 100; i++) &#123;
      await doSomething(job.data);
      progress += 10;
      job.progress(progress);
    &#125;
    return &#123;&#125;;
  &#125;
&#125;</code></pre>
<p>The decorated method (e.g., <code>transcode()</code>) is called whenever the worker is idle and there are jobs to process in the queue. This handler method receives the <code>job</code> object as its only argument. The value returned by the handler method is stored in the job object and can be accessed later on, for example in a listener for the completed event.</p>
<p><code>Job</code> objects have multiple methods that allow you to interact with their state. For example, the above code uses the <code>progress()</code> method to update the job&#39;s progress. See <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#job">here</a> for the complete <code>Job</code> object API reference.</p>
<p>You can designate that a job handler method will handle <strong>only</strong> jobs of a certain type (jobs with a specific <code>name</code>) by passing that <code>name</code> to the <code>@Process()</code> decorator as shown below. You can have multiple <code>@Process()</code> handlers in a given consumer class, corresponding to each job type (<code>name</code>). When you use named jobs, be sure to have a handler corresponding to each name.</p>
<pre><code class="language-typescript">
@Process(&#39;transcode&#39;)
async transcode(job: Job&lt;unknown&gt;) &#123; ... &#125;</code></pre>
<h4 appAnchor id="event-listeners"><span>Event listeners</span></h4>
<p>Bull generates a set of useful events when queue and/or job state changes occur. Nest provides a set of decorators that allow subscribing to a core set of standard events. These are exported from the <code>@nestjs/bull</code> package.</p>
<p>Event listeners must be declared within a <a href="techniques/queues#consumers">consumer</a> class (i.e., within a class decorated with the <code>@Processor()</code> decorator). To listen for an event, use one of the decorators in the table below to declare a handler for the event. For example, to listen to the event emitted when a job enters the active state in the <code>audio</code> queue, use the following construct:</p>
<pre><code class="language-typescript">
import &#123; Processor, Process &#125; from &#39;@nestjs/bull&#39;;
import &#123; Job &#125; from &#39;bull&#39;;

@Processor(&#39;audio&#39;)
export class AudioConsumer &#123;

  @OnQueueActive()
  onActive(job: Job) &#123;
    console.log(
      `Processing job $&#123;job.id&#125; of type $&#123;job.name&#125; with data $&#123;job.data&#125;...`,
    );
  &#125;
  ...</code></pre>
<p>Since Bull operates in a distributed (multi-node) environment, it defines the concept of event locality. This concept recognizes that events may be triggered either entirely within a single process, or on shared queues from different processes. A <strong>local</strong> event is one that is produced when an action or state change is triggered on a queue in the local process. In other words, when your event producers and consumers are local to a single process, all events happening on queues are local.</p>
<p>When a queue is shared across multiple processes, we encounter the possibility of <strong>global</strong> events. For a listener in one process to receive an event notification triggered by another process, it must register for a global event.</p>
<p>Event handlers are invoked whenever their corresponding event is emitted. The handler is called with the signature shown in the table below, providing access to information relevant to the event. We discuss one key difference between local and global event handler signatures below.</p>
<table>
  <tr>
    <th>Local event listeners</th>
    <th>Global event listeners</th>
    <th>Handler method signature / When fired</th>
  </tr>
  <tr>
    <td><code>@OnQueueError()</code></td><td><code>@OnGlobalQueueError()</code></td><td><code>handler(error: Error)</code> - An error occurred. <code>error</code> contains the triggering error.</td>
  </tr>
  <tr>
    <td><code>@OnQueueWaiting()</code></td><td><code>@OnGlobalQueueWaiting()</code></td><td><code>handler(jobId: number | string)</code> - A Job is waiting to be processed as soon as a worker is idling. <code>jobId</code> contains the id for the job that has entered this state.</td>
  </tr>
  <tr>
    <td><code>@OnQueueActive()</code></td><td><code>@OnGlobalQueueActive()</code></td><td><code>handler(job: Job)</code> - Job <code>job</code>has started. </td>
  </tr>
  <tr>
    <td><code>@OnQueueStalled()</code></td><td><code>@OnGlobalQueueStalled()</code></td><td><code>handler(job: Job)</code> - Job <code>job</code> has been marked as stalled. This is useful for debugging job workers that crash or pause the event loop.</td>
  </tr>
  <tr>
    <td><code>@OnQueueProgress()</code></td><td><code>@OnGlobalQueueProgress()</code></td><td><code>handler(job: Job, progress: number)</code> - Job <code>job</code>'s progress was updated to value <code>progress</code>.</td>
  </tr>
  <tr>
    <td><code>@OnQueueCompleted()</code></td><td><code>@OnGlobalQueueCompleted()</code></td><td><code>handler(job: Job, result: any)</code> Job <code>job</code> successfully completed with a result <code>result</code>.</td>
  </tr>
  <tr>
    <td><code>@OnQueueFailed()</code></td><td><code>@OnGlobalQueueFailed()</code></td><td><code>handler(job: Job, err: Error)</code> Job <code>job</code> failed with reason <code>err</code>.</td>
  </tr>
  <tr>
    <td><code>@OnQueuePaused()</code></td><td><code>@OnGlobalQueuePaused()</code></td><td><code>handler()</code> The queue has been paused.</td>
  </tr>
  <tr>
    <td><code>@OnQueueResumed()</code></td><td><code>@OnGlobalQueueResumed()</code></td><td><code>handler(job: Job)</code> The queue has been resumed.</td>
  </tr>
  <tr>
    <td><code>@OnQueueCleaned()</code></td><td><code>@OnGlobalQueueCleaned()</code></td><td><code>handler(jobs: Job[], type: string)</code> Old jobs have been cleaned from the queue. <code>jobs</code> is an array of cleaned jobs, and <code>type</code> is the type of jobs cleaned.</td>
  </tr>
  <tr>
    <td><code>@OnQueueDrained()</code></td><td><code>@OnGlobalQueueDrained()</code></td><td><code>handler()</code> Emitted whenever the queue has processed all the waiting jobs (even if there can be some delayed jobs not yet processed).</td>
  </tr>
  <tr>
    <td><code>@OnQueueRemoved()</code></td><td><code>@OnGlobalQueueRemoved()</code></td><td><code>handler(job: Job)</code> Job <code>job</code> was successfully removed.</td>
  </tr>
</table>

<p>When listening for global events, the method signatures can be slightly different from their local counterpart. Specifically, any method signature that receives <code>job</code> objects in the local version, instead receives a <code>jobId</code> (<code>number</code>) in the global version. To get a reference to the actual <code>job</code> object in such a case, use the <code>Queue#getJob</code> method. This call should be awaited, and therefore the handler should be declared <code>async</code>. For example:</p>
<pre><code class="language-typescript">
@OnGlobalQueueCompleted()
async onGlobalCompleted(jobId: number, result: any) &#123;
  const job = await this.immediateQueue.getJob(jobId);
  console.log(&#39;(Global) on completed: job &#39;, job.id, &#39; -&gt; result: &#39;, result);
&#125;</code></pre>
<blockquote class="
info "><strong>Hint</strong> To access the <code>Queue</code> object (to make a <code>getJob()</code> call), you must of course inject it. Also, the Queue must be registered in the module where you are injecting it.
</blockquote>
<p>In addition to the specific event listener decorators, you can also use the generic <code>@OnQueueEvent()</code> decorator in combination with either <code>BullQueueEvents</code> or <code>BullQueueGlobalEvents</code> enums. Read more about events <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#events">here</a>.</p>
<h4 appAnchor id="queue-management"><span>Queue management</span></h4>
<p>Queue&#39;s have an API that allows you to perform management functions like pausing and resuming, retrieving the count of jobs in various states, and several more. You can find the full queue API <a rel='nofollow' target='_blank' href="https://github.com/OptimalBits/bull/blob/master/REFERENCE.md#queue">here</a>. Invoke any of these methods directly on the <code>Queue</code> object, as shown below with the pause/resume examples.</p>
<p>Pause a queue with the <code>pause()</code> method call. A paused queue will not process new jobs until resumed, but current jobs being processed will continue until they are finalized.</p>
<pre><code class="language-typescript">
await audioQueue.pause();</code></pre>
<p>To resume a paused queue, use the <code>resume()</code> method, as follows:</p>
<pre><code class="language-typescript">
await audioQueue.resume();</code></pre>
<h4 appAnchor id="async-configuration"><span>Async configuration</span></h4>
<p>You may want to pass your queue options asynchronously instead of statically. In this case, use the <code>registerQueueAsync()</code> method, which provides several ways to deal with async configuration.</p>
<p>One approach is to use a factory function:</p>
<pre><code class="language-typescript">
BullModule.registerQueueAsync(&#123;
  name: &#39;audio&#39;,
  useFactory: () =&gt; (&#123;
    redis: &#123;
      host: &#39;localhost&#39;,
      port: 6379,
    &#125;,
  &#125;),
&#125;);</code></pre>
<p>Our factory behaves like any other <a rel='nofollow' target='_blank' href="https://docs.nestjs.com/fundamentals/async-providers">asynchronous provider</a> (e.g., it can be <code>async</code> and it&#39;s able to inject dependencies through <code>inject</code>).</p>
<pre><code class="language-typescript">
BullModule.registerQueueAsync(&#123;
  name: &#39;audio&#39;,
  imports: [ConfigModule],
  useFactory: async (configService: ConfigService) =&gt; (&#123;
    redis: &#123;
      host: configService.get(&#39;QUEUE_HOST&#39;),
      port: +configService.get(&#39;QUEUE_PORT&#39;),
    &#125;,
  &#125;),
  inject: [ConfigService],
&#125;);</code></pre>
<p>Alternatively, you can use the <code>useClass</code> syntax:</p>
<pre><code class="language-typescript">
BullModule.registerQueueAsync(&#123;
  name: &#39;audio&#39;,
  useClass: BullConfigService,
&#125;);</code></pre>
<p>The construction above will instantiate <code>BullConfigService</code> inside <code>BullModule</code> and use it to provide an options object by calling <code>createBullOptions()</code>. Note that this means that the <code>BullConfigService</code> has to implement the <code>BullOptionsFactory</code> interface, as shown below:</p>
<pre><code class="language-typescript">
@Injectable()
class BullConfigService implements BullOptionsFactory &#123;
  createBullOptions(): BullModuleOptions &#123;
    return &#123;
      redis: &#123;
        host: &#39;localhost&#39;,
        port: 6379,
      &#125;,
    &#125;;
  &#125;
&#125;</code></pre>
<p>In order to prevent the creation of <code>BullConfigService</code> inside <code>BullModule</code> and use a provider imported from a different module, you can use the <code>useExisting</code> syntax.</p>
<pre><code class="language-typescript">
BullModule.registerQueueAsync(&#123;
  name: &#39;audio&#39;,
  imports: [ConfigModule],
  useExisting: ConfigService,
&#125;);</code></pre>
<p>This construction works the same as <code>useClass</code> with one critical difference - <code>BullModule</code> will lookup imported modules to reuse an existing <code>ConfigService</code> instead of instantiating a new one.</p>
<h4 appAnchor id="example"><span>Example</span></h4>
<p>A working example is available <a rel='nofollow' target='_blank' href="https://github.com/nestjs/nest/tree/master/sample/26-queues">here</a>.</p>

</div>

